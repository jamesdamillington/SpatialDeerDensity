{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Spatial Deer Distribution using R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This notebook contains **R code** and exercises associated with concepts discussed in lecture and [Millington _et al._ (2010)](http://dx.doi.org/10.1016/j.foreco.2009.12). The notebook _Modelling Spatial Deer Distribution using Python_ provides the same examples but using python code. Compare the two notebooks to understand how the languages differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use install.packages(LIBRARY_NAME) to install, then lines below import\n",
    "\n",
    "library(ggplot2)    #for nicer plotting\n",
    "library(caret)      #for cross-validation\n",
    "library(raster)     #for spatial estimation\n",
    "library(viridis)    #for plotting palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Section 1: Loading and Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOI200 <- read.csv(\"data/LOI200.csv\", header = T) #read the file to a data.frame (assumes data are in same directory as notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now view the first few lines of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(LOI200)                                 #view the first part of the data (to check it read properly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see a summary of the variables in the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(LOI200)                              #view a summary of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then we use some simple plotting functions to visualise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#matrix scatter plot for 2nd to 6th columns (R is 1 indexed!)\n",
    "pairs(LOI200[,2:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#simple scatter with axis labels\n",
    "plot(LOI200$DistanceLC, LOI200$logDD, xlab = \"Distance LC (km)\", ylab = \"log(Deer Density)\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Correlation and Simple Linear Regression\n",
    "\n",
    "Now that we have familiarised ourselves with the data, we can do some simple correlations to examine the relationship of deer density with the distance to the nearest lowland conifer stand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cor.test(LOI200$DistanceLC, LOI200$logDD, method = \"pearson\")       #calculate pearson correlation coefficient (r)\n",
    "cor.test(LOI200$DistanceLC, LOI200$logDD, method = \"kendall\")       #calculate kendall's correlation coefficient (tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We find some weak, but statistically significant (at the 95% confidence level) correlations. \n",
    "\n",
    "The next piece of analysis we will do is to fit simple linear regression models to predict log(deer density) from environmental co-variates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dlc <- lm(logDD ~ DistanceLC, data = LOI200)       #fit a model and assign to a model object named mod_dlc\n",
    "summary(mod_dlc)                                       #get the summary of the fitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model looks using a scatter plot of the variables and use the fit model (`mod_dlc`) to add a regression line (using the `abline` function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(LOI200$DistanceLC, LOI200$logDD)         \n",
    "abline(mod_dlc)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [ggplot2 library in R](https://ggplot2.tidyverse.org/) is similar to the seaborn package in python in that it makes generating nice-looking plots much easier than using the base R functionality. For example, the following code improved the scatter plot above and produces something like seaborn's `regplot`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires ggplot2 library\n",
    "ggplot(LOI200, aes(x=DistanceLC, y=logDD)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method=lm , color=\"darkblue\", fill=\"lightblue\", se=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The `names` function is useful in R to check what items we can get from the fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(mod_dlc)                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can see that one of items is the model residuals. We can use this to plot our own histogram of model residuals for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "hist(mod_dlc$residuals)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This plot shows that the residuals are reasonably normally distributed and that we are likely not violating the assumptions of simple linear regression. \n",
    "\n",
    "We can check further assumptions using the built-in diagnostic plotting functions provided in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plot(mod_dlc)            #plot model diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "You can find out more about how to interpret these plots [here](https://analyticspro.org/2016/03/07/r-tutorial-how-to-use-diagnostic-plots-for-regression-models/) (as for our histogram of residuals, these plots show that the assumptions of simple linear regression have been met in this model). \n",
    "\n",
    "To get some other useful model outputs, we need to get items from the model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(summary(mod_dlc))          #check what items we can get from the SUMMARY of the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mod_dlc)$coefficients    #directly access the model coefficients (with t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mod_dlc)$r.squared       #directly access the r.squared of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's harder to directly access the model p-value, but [it is possible with a function](http://stackoverflow.com/a/5587781).\n",
    "\n",
    "The code in this section has provided all we need to know to calculate the values in the first row of Table 1 in Millington et al. (2010)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.\n",
    "Use the code above to help you calculate values for the four other variables in Table 1 that have p < 0.1. Check you can get values from your code that correspond to those in Table 1 of Millington _et al._ (2010) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Section 3. Multiple linear regression models\n",
    "\n",
    "Fitting linear regression models with more than one are almost as straighforward as for simple (univariate) linear regression models, we just need to add the additional variables into the model equation. Here's the 'best model' containing two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dlc_dbh <- lm(logDD ~ DistanceLC + NewDBH, data = LOI200)   #fit a model and assign to a model object\n",
    "summary(mod_dlc_dbh)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To get a kendall correlation coefficient we need to output the predicted logDDs and then test using `cor.test` with `method = \"kendall\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.mod_dlc_dbh <- predict(mod_dlc_dbh)\n",
    "cor.test(LOI200$logDD, pred.mod_dlc_dbh, method = \"kendall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Task 2.\n",
    "Use the code above to write your own code to calculate the values in Table 2 of Millington _et al._ (2010) for the Full Model (all values except for cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Section 4. Cross-validation\n",
    "\n",
    "To complete the bottom two lines of Table 2 in Millington _et al._ (2010) we need to run cross-validation. In R, we can use functionality in [the `caret` package](https://topepo.github.io/caret/) for cross-validation.\n",
    "\n",
    "To do a single 5-fold cross validation for the `mod_dlc_dbh` model we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires caret library\n",
    "#first specify the splitting\n",
    "fivefold <- trainControl(method=\"cv\", number = 5, savePredictions = T) #savePredictions to create pred below\n",
    "\n",
    "#then run the cv\n",
    "set.seed(5)\n",
    "cv_mod_dlc_dbh <- train(logDD~DistanceLC+NewDBH,data=LOI200, method=\"lm\", trControl=fivefold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can see results by accessing `pred` in the caret object created by `train` (see `help(train)` for all the possible outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mod_dlc_dbh$pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now, to get the r2 and tau for these predicted logDD from the cross-validation we use the simple `cor()` function again, passing columns for observed logDD (`obs`) and predicted logDD (`pred`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2obs <- cor.test(LOI200$logDD, pred.mod_dlc_dbh, method = \"pearson\")$estimate^2  #need to square pearson r to get r2\n",
    "tauobs <- cor.test(LOI200$logDD, pred.mod_dlc_dbh, method = \"kendall\")$estimate\n",
    "print(paste(\"r2 (obs): \",round(r2obs,3)))\n",
    "print(paste(\"tau (obs): \",round(tauobs,3)))\n",
    "\n",
    "r2cv <- cor.test(cv_mod_dlc_dbh$pred$obs, cv_mod_dlc_dbh$pred$pred, method=\"pearson\")$estimate^2  #need to square pearson r to get r2\n",
    "taucv <- cor.test(cv_mod_dlc_dbh$pred$obs, cv_mod_dlc_dbh$pred$pred, method=\"kendall\")$estimate\n",
    "print(paste(\"r2 (cv): \",round(r2cv,3)))  \n",
    "print(paste(\"tau (cv): \",round(taucv,3))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "But note how the caption of Table 2 in Millington _et al._ (2010) indicates that \n",
    ">\"estimates for cross-validation results are 95% confidence intervals calculated from mean and variance of 100 repetitions.\"\n",
    "\n",
    "To do this we'll create a loop to run the cross-validation multiple times, storing the results so we can calculate the mean and variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_r <- vector()       #vector to hold r results for each cross-validation \n",
    "cv_t <- vector()       #vector to hold tau results for each cross-validation\n",
    "\n",
    "for (i in 1:100)\n",
    "{\n",
    "  set.seed(i)\n",
    "  out <- train(logDD~DistanceLC+NewDBH,data=LOI200, method=\"lm\", trControl=fivefold)\n",
    "  \n",
    "  #store the correlation results\n",
    "  cv_r <- c(cv_r, cor.test(out$pred$obs, out$pred$pred, method=\"pearson\")$estimate)\n",
    "  cv_t <- c(cv_t, cor.test(out$pred$obs, out$pred$pred, method=\"kendall\")$estimate)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "So, now we can calculate mean and variance for r2 and tau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "mr <- mean(cv_r^2)\n",
    "mt <- mean(cv_t)\n",
    "vr <- 1.96 * var(cv_r^2)   #1.96 for 95% - forgot this in original!\n",
    "vt <- 1.96 * var(cv_t)     #1.96 for 95% - forgot this in original!\n",
    "\n",
    "print(round(mr,3))\n",
    "print(round(mt,3))\n",
    "print(round(vr,3))\n",
    "print(round(vt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[NB: Values for error are slightly different from the paper due to randomisation. Also, we don't use the _\"repeatedcv\"_ option in `trainControl` as that provides model results averaged over all folds, whereas we want to average results over all cross-validations.]\n",
    "\n",
    "### Task 3.\n",
    "\n",
    "Build on the code above to calculate the cross-validation values for the 'Full' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Section 5. Spatial Estimation\n",
    "Later in Millington _et al._ (2010) models fit from the sample data (at 51 locations) were used to predict deer density across a subsection of the study area. We can do this in R using the functionality in the `raster` package.\n",
    "\n",
    "First load a raster map in which the value of each pixel is the distance to the nearest lowland conifer pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library(raster)\n",
    "#library(viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistanceLC <- raster(\"data/LOI200_dlc_km.asc\")      #to create the raster object simply provide path to file\n",
    "plot(DistanceLC)                               #check it looks about right\n",
    "names(DistanceLC) <- \"DistanceLC\"              #assign name that matched that used in the regression model for this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This first map is all we need to predict deer density based on distance to lowland conifer only we do this using the predict functionality of the raster package to apply the model parameter estimates to the spatial map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dlc <- predict(DistanceLC, mod_dlc)         #first term is the raster, second is the model we fit above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(p_dlc, col=viridis_pal(option=\"D\")(255))   #use viridis palette to match python output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The map we have made is of log(deer density) - to get to linear deer density we need to raise to power 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(10^p_dlc, col=viridis_pal(option=\"D\")(255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Task 4.\n",
    "\n",
    "Use code in this section to create a predicted deer density map for the 'best model' (i.e. using `LOI200_dlc_km.asc` and `LOI200_Meandbh_cm.asc` as predictor maps).\n",
    "\n",
    "_Hint:_ to predict a model across multiple raster grids you will need to create a [raster stack](https://rspatial.org/raster/spatial/4-rasterdata.html#rasterstack-and-rasterbrick). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Additional (not copied in python) \n",
    "\n",
    "## Section 6. Map Visualisation\n",
    "\n",
    "We can make the colours for look like in Millington _et al._ (2010) using functionality in some other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(colorspace)  #for heat_hcl\n",
    "library(rasterVis)  #for rasterTheme\n",
    "library(lattice)     #for levelplot\n",
    "\n",
    "myTheme <- rasterTheme(region = heat_hcl(12, c = c(80,30), l = c(30,90), power = c(1/5, 1.5)))   #see https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf\n",
    "\n",
    "levelplot(10^p_dlc, par.settings = myTheme, margin = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "And [we can](http://stackoverflow.com/a/16848471) scale the shades to compare directly between other predictions later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levelplot(10^p_dlc, par.settings = myTheme, at=seq(5, 35, length=12), colorkey=list(at=seq(5, 35, length=12)), margin = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "So far we have a map of predicted deer density across the entire study area. However, sample data were collected only in hardwood stands so really we should only predict for hardwood stands. To do this we need to load a land cover map and then create a 'mask' (a map indicating hardwood pixels only). \n",
    "\n",
    "Load a raster map in which each pixel is a categorical land cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LandCov <- raster(\"data/covtyp_rc.asc\")             #simply provide path to file\n",
    "plot(LandCov)                                  #check it looks about right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The landcov map indicates categories by numbers; we can change this so they are more appropriately represented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LandCov <- ratify(LandCov)     #tell R that the landcov raster is categorical                    \n",
    "rat <- levels(LandCov)[[1]]    #apply the levels (i.e. categories) \n",
    "rat$landcover <- c(\"Aspen\", \"Lowland Conifer\", \"Other Decid\", \"Open\", \"Other EG\", \"Hardwood\")   #Name the categories Aspen = 1, Lowland Conifer = 2, etc\n",
    "levels(LandCov) <- rat         #apply the named categories to the raster\n",
    "plot(LandCov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Note that the regular raster plot() function still has not picked up the categories. We can plot the categorical map more nicely using functionality in the `rasterVis` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levelplot(LandCov, att = 'landcover', col.regions=c('wheat1', 'orange2', 'darkolivegreen', 'gray', 'wheat2', 'forestgreen'))  #something weired with order of the colours vs levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now let's create the hardwood mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdwd <- raster(\"data/covtyp_rc.asc\")   #simply provide path to file\n",
    "hdwd[LandCov != 6] <- NA          #if a pixel is not hardwood in LandCov set to NA in hdwd\n",
    "plot(hdwd)                        #check the mask looks right (compare to the previous map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now we can apply the mask to the p_dlc map for all pixels (using the raster `mask()` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dlc <- mask(p_dlc, hdwd)    #mask to see prediction for hardwood only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "And re-plot to check it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levelplot(10^p_dlc, par.settings = myTheme, at=seq(5, 35, length=12), colorkey=list(at=seq(5, 35, length=12)), margin = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Great, we've created a map of deer density as predicted from distance to nearest lowland conifer what if we wanted to predict using a multivariate model? To do that we need to create raster `stack` of (maps of) our predictor variables.\n",
    "\n",
    "First load in another predictor map - this one in which the value of each pixel is the mean dbh of the local (200m) region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDBH <- raster(\"data/LOI200_Meandbh_cm.asc\")      #simply provide file name\n",
    "plot(NewDBH)                                   #check it looks about right\n",
    "names(NewDBH) <- \"NewDBH\"                      #assign name that matched that used in the regression model for this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now create the raster `stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_dlc_dbh <- stack(DistanceLC, NewDBH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To predict using a multivariate model is now just the same as before, except the stack is passed instead of the single raster map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dlc_dbh <- predict(stack_dlc_dbh, mod_dlc_dbh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Let's apply the mask then plot it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dlc_dbh <- mask(p_dlc_dbh, hdwd)\n",
    "levelplot(10^p_dlc_dbh, par.settings = myTheme, at=seq(5, 35, length=12), colorkey=list(at=seq(5, 35, length=12)), margin = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The plot just created should look pretty similar to Fig 5a in Millington et al. (2010) [although not identical]\n",
    "\n",
    "Absent from the map we just created is the shading to indicate the location of lowland conifer stands (distance to which is an important predictor in the model). To add this shading first we need to create the shaded layer (similar to creating the `hdwd` object above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC <- raster(\"data/covtyp_rc.asc\")\n",
    "LC[LandCov != 2] <- NA\n",
    "LC <- ratify(LC)\n",
    "LCrat <- levels(LC)[[1]]\n",
    "LCrat$landcover <- c(\"Lowland Conifer\")\n",
    "levels(LC) <- LCrat\n",
    "levelplot(LC, col.regions = c('darkolivegreen'), margin = F, colorkey = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To combine layers in a single plot we need to create separate plot objects first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCplot <- levelplot(LC, col.regions = c('darkolivegreen'), margin = F, colorkey = F)\n",
    "DLCplot <- levelplot(10^p_dlc_dbh, par.settings = myTheme, at=seq(5, 35, length=12), colorkey=list(at=seq(5, 35, length=12)), margin = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then [combine](https://oscarperpinan.github.io/rastervis/#levelplot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLCplot + as.layer(LCplot, under = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ta-da!**\n",
    "\n",
    "### Task 5.\n",
    "Use the `LOI200_dlc_km_scenario.asc` file to produce a predicted deer density map for a scenario in which selected lowland conifer stands have been removed from the landscape (as shown in Fig 6 of Millington _et al._ 2010)\n",
    "\n",
    "_Hint:_ as in Task 4 you'll need to use a raster stack, but this time using `LOI200_dlc_km_scenario.asc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Visualisation\n",
    "\n",
    "The ggplot2 library has made plotting in R much easier. ggplot did not exist when the original analysis for Millington _et al._ (2010) was done and so the plots in the paper look a little different from how they would look if created today using ggplot. Below shows the process used to create Figure 3 in Millington _et al._ (2010) using the base R functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the model and potentially add 95% confidence bands (the red dotted lines) to our plots we can write a short user-defined function (see below). There's no need to try to understand the guts of how this functions works, but  notice that in the first line of the function definition the function expects to receieve:\n",
    "\n",
    "1. something called `model`\n",
    "2. possibly a TRUE/FALSE for `conf.bands`\n",
    "3. possibly a value for `levels`\n",
    "4. possibly some other parameters\n",
    "\n",
    "Argument 1. should be a fitted simple linear regression model (like `mod_dlc`), 2. indicates whether we want confidence bands plotted (default is no bands) and 3. is the level of confidence we want any bands to illustrate (default is 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is an edited version of confidence.band function by Derek Young and David Hunter from http://sites.stat.psu.edu/~dhunter/R/confidence.band.r\n",
    "regression.plot = function(model, conf.bands = FALSE, levels=0.95, segments=50, col.points=palette()[1], \n",
    "                           col.line=palette()[1], col.bands=palette()[2], \n",
    "                           lty.line=1, lty.bands=2, ...) {\n",
    "  if (attr(model$terms,\"intercept\")!=1 || length(model$coef) !=2) {\n",
    "    stop(paste(\"regression.plot only works for simple linear regression\\n\",\n",
    "               \"with one predictor and an intercept\"))\n",
    "  }\n",
    "  plot(model$model[,2:1], col=col.points, ...)\n",
    "  abline(model, col=col.line, lty=lty.line, lwd=2)\n",
    "  if(conf.bands)\n",
    "  {\n",
    "    angles=(0:segments)*pi/segments\n",
    "    halfcircle = cbind(cos(angles), sin(angles))  \n",
    "    chol.shape = chol(vcov(model))\n",
    "    slopes = (halfcircle %*% chol.shape)[,2]\n",
    "    angles = angles+angles[which.max(slopes)]\n",
    "    halfcircle = cbind(cos(angles), sin(angles))  \n",
    "    center = model$coef\n",
    "    radius = sqrt(2*qf(levels, 2, df.residual(model)))\n",
    "    for (r in radius) {\n",
    "      for (i in 1:2) {\n",
    "        halfcircle = -halfcircle\n",
    "        ellipse = sweep(r*(halfcircle %*% chol.shape), 2, center, \"+\")\n",
    "        int = ellipse[,1]\n",
    "        slope = ellipse[,2]\n",
    "        x = -diff(int)/diff(slope)\n",
    "        y = int[-1]+slope[-1]*x\n",
    "        lines(x, y, lwd=2, lty=lty.bands, col=col.bands)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This function is an example of how you can write your own functions just like in other languages (like Python). We can use the function to plot `DistanceLC` against `logDD` with confidence bannds as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.plot(mod_dlc, conf.bands = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To create a plot like Figure 3 in Millington _et al._ (2010) we need to tell R to create a plot with two rows of three panes (and reduce the margins) by setting the graphical parameters using `par()`. Any plots we subsequently make will be placed in each of these panes. For example, using a loop that plots `mod_dlc` five times we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "default.par <- par()   #save default plotting parameters for later if needed\n",
    "par(mfrow=c(2,3), mar=c(4,4,2,1))  #now edit the plotting parameters\n",
    "\n",
    "for(i in 1:5)\n",
    "{\n",
    "  regression.plot(mod_dlc, conf.bands = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "NB, plotting like this is made much easier using the [facet](https://ggplot2.tidyverse.org/reference/facet_grid.html) functionality in the [ggplot2 library](https://ggplot2.tidyverse.org/))\n",
    "\n",
    "To return to the original graphical parameters (i.e. one-pane plots) we can use the `default.par` object we created above (we can check but ignore any error messages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(default.par) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check plotting has returned to normal you could re-run the last loop again"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
